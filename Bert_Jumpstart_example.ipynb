{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529f3b80-08be-40eb-8434-5c76c7bc1c8e",
   "metadata": {},
   "source": [
    "# Spam detector using Jumpstart\n",
    "Document: https://sagemaker.readthedocs.io/en/stable/algorithms/text/text_classification_tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd9bc55-77c0-4bc8-8d0b-bd533f5bf044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = \"ap-northeast-1\"\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776488ad-064b-4b82-b280-2e8110c28dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defdd98-53dc-4954-951b-01e18c156776",
   "metadata": {},
   "source": [
    "Training dataset is here.\n",
    "https://www.kaggle.com/datasets/tmehul/spamcsv?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b22663-60cc-4e94-a5fe-5e6b368d8fd7",
   "metadata": {},
   "source": [
    "Create **training-datqsets/SST** folder in s3 and place **data.csv** in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5bd2d4-0d41-499c-8341-b47b339d13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "from sagemaker.jumpstart.utils import get_jumpstart_content_bucket\n",
    "\n",
    "training_data_prefix = \"training-datasets/SST/\"\n",
    "training_dataset_s3_path = f\"s3://sagemaker-automated-execution-533267358966-ap-northeast-1/{training_data_prefix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9301d6b-e1cd-46b0-ad8b-94ee11c6efce",
   "metadata": {},
   "source": [
    "Enabling debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ca2187-97d7-453a-89a4-b570176ec893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, rule_configs\n",
    "debugger_rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4d3df-4276-4d09-866a-1738da4a3ccf",
   "metadata": {},
   "source": [
    "Choose instance from here.  https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/notebooks-available-instance-types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67842e56-e7fb-429f-adde-93bd49c3ce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2' with wildcard version identifier '*'. You can pin to version '3.0.8' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    hyperparameters={\"epochs\": \"5\", \"batch_size\": \"64\",  \"use_fp16\": \"True\", \"train_only_top_layer\":\"True\"},\n",
    "    instance_type= \"ml.m5.4xlarge\",\n",
    "    rules=debugger_rules\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36f6870-77f9-4b65-bc85-f8bf697c0201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': '\"5\"',\n",
       " 'batch_size': '\"64\"',\n",
       " 'use_fp16': '\"True\"',\n",
       " 'train_only_top_layer': '\"True\"',\n",
       " 'optimizer': '\"adamw\"',\n",
       " 'learning_rate': '\"2e-05\"',\n",
       " 'warmup_steps_fraction': '\"0.1\"',\n",
       " 'beta_1': '\"0.9\"',\n",
       " 'beta_2': '\"0.999\"',\n",
       " 'momentum': '\"0.9\"',\n",
       " 'epsilon': '\"1e-06\"',\n",
       " 'rho': '\"0.95\"',\n",
       " 'initial_accumulator_value': '\"0.1\"',\n",
       " 'early_stopping': '\"False\"',\n",
       " 'early_stopping_patience': '\"5\"',\n",
       " 'early_stopping_min_delta': '\"0.0\"',\n",
       " 'dropout_rate': '\"0.2\"',\n",
       " 'regularizers_l2': '\"0.01\"',\n",
       " 'validation_split_ratio': '\"0.2\"',\n",
       " 'reinitialize_top_layer': '\"Auto\"'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428def5e-a39b-4fd7-a592-ab11e76b6853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-10-17-57-13-595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:57:19 Starting - Starting the training job...\n",
      "2025-03-10 17:57:47 Starting - Preparing the instances for trainingLossNotDecreasing: InProgress\n",
      "Overfit: InProgress\n",
      "VanishingGradient: InProgress\n",
      "...\n",
      "2025-03-10 17:58:18 Downloading - Downloading the training image......\n",
      "2025-03-10 17:59:07 Training - Training image download completed. Training in progress..\u001b[34m2025-03-10 17:59:23.048027: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:23.048173: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:23.073659: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,030 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,041 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,067 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,084 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,100 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:25,110 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"code\": \"/opt/ml/input/data/code\",\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"64\",\n",
      "        \"beta_1\": \"0.9\",\n",
      "        \"beta_2\": \"0.999\",\n",
      "        \"dropout_rate\": \"0.2\",\n",
      "        \"early_stopping\": \"False\",\n",
      "        \"early_stopping_min_delta\": \"0.0\",\n",
      "        \"early_stopping_patience\": \"5\",\n",
      "        \"epochs\": \"5\",\n",
      "        \"epsilon\": \"1e-06\",\n",
      "        \"initial_accumulator_value\": \"0.1\",\n",
      "        \"learning_rate\": \"2e-05\",\n",
      "        \"momentum\": \"0.9\",\n",
      "        \"optimizer\": \"adamw\",\n",
      "        \"regularizers_l2\": \"0.01\",\n",
      "        \"reinitialize_top_layer\": \"Auto\",\n",
      "        \"rho\": \"0.95\",\n",
      "        \"train_only_top_layer\": \"True\",\n",
      "        \"use_fp16\": \"True\",\n",
      "        \"validation_split_ratio\": \"0.2\",\n",
      "        \"warmup_steps_fraction\": \"0.1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"code\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-10-17-57-13-595\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/input/data/code/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":\"64\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"5\",\"epsilon\":\"1e-06\",\"initial_accumulator_value\":\"0.1\",\"learning_rate\":\"2e-05\",\"momentum\":\"0.9\",\"optimizer\":\"adamw\",\"regularizers_l2\":\"0.01\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"use_fp16\":\"True\",\"validation_split_ratio\":\"0.2\",\"warmup_steps_fraction\":\"0.1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"code\",\"model\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/input/data/code/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"code\":\"/opt/ml/input/data/code\",\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"64\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":\"5\",\"epsilon\":\"1e-06\",\"initial_accumulator_value\":\"0.1\",\"learning_rate\":\"2e-05\",\"momentum\":\"0.9\",\"optimizer\":\"adamw\",\"regularizers_l2\":\"0.01\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"True\",\"use_fp16\":\"True\",\"validation_split_ratio\":\"0.2\",\"warmup_steps_fraction\":\"0.1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-10-17-57-13-595\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/input/data/code/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"64\",\"--beta_1\",\"0.9\",\"--beta_2\",\"0.999\",\"--dropout_rate\",\"0.2\",\"--early_stopping\",\"False\",\"--early_stopping_min_delta\",\"0.0\",\"--early_stopping_patience\",\"5\",\"--epochs\",\"5\",\"--epsilon\",\"1e-06\",\"--initial_accumulator_value\",\"0.1\",\"--learning_rate\",\"2e-05\",\"--momentum\",\"0.9\",\"--optimizer\",\"adamw\",\"--regularizers_l2\",\"0.01\",\"--reinitialize_top_layer\",\"Auto\",\"--rho\",\"0.95\",\"--train_only_top_layer\",\"True\",\"--use_fp16\",\"True\",\"--validation_split_ratio\",\"0.2\",\"--warmup_steps_fraction\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CODE=/opt/ml/input/data/code\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_2=0.999\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING=False\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_MIN_DELTA=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=5\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_EPSILON=1e-06\u001b[0m\n",
      "\u001b[34mSM_HP_INITIAL_ACCUMULATOR_VALUE=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adamw\u001b[0m\n",
      "\u001b[34mSM_HP_REGULARIZERS_L2=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE_TOP_LAYER=Auto\u001b[0m\n",
      "\u001b[34mSM_HP_RHO=0.95\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_ONLY_TOP_LAYER=True\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FP16=True\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_SPLIT_RATIO=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS_FRACTION=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.9 transfer_learning.py --batch_size 64 --beta_1 0.9 --beta_2 0.999 --dropout_rate 0.2 --early_stopping False --early_stopping_min_delta 0.0 --early_stopping_patience 5 --epochs 5 --epsilon 1e-06 --initial_accumulator_value 0.1 --learning_rate 2e-05 --momentum 0.9 --optimizer adamw --regularizers_l2 0.01 --reinitialize_top_layer Auto --rho 0.95 --train_only_top_layer True --use_fp16 True --validation_split_ratio 0.2 --warmup_steps_fraction 0.1\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34mInstalling dependencies from /opt/ml/code/tensorflow_requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: There was an error checking the latest version of pip.\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_prepack_script_utilities/sagemaker_jumpstart_prepack_script_utilities-1.0.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sagemaker-jumpstart-prepack-script-utilities\u001b[0m\n",
      "\u001b[34mSuccessfully installed sagemaker-jumpstart-prepack-script-utilities-1.0.0\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:27.700107: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:27.700267: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2025-03-10 17:59:27.725893: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mRunning training scripts with arguments: Namespace(model_dir='/opt/ml/model', train='/opt/ml/input/data/training', validation=None, pretrained_model='/opt/ml/input/data/model', hosts=['algo-1'], current_host='algo-1', verbose_one_line_per_epoch=2, model_url=None, text_processor_url=None, checkpoint_save_best_only='True', seed=123, warmup_steps_fraction=0.1, reinitialize_top_layer='Auto', train_only_top_layer='True', validation_split_ratio=0.2, early_stopping='False', early_stopping_patience=5, early_stopping_min_delta=0.0, dropout_rate=0.2, regularizers_l2=0.01, epochs=5, batch_size=64, optimizer='adamw', learning_rate=2e-05, beta_1=0.9, beta_2=0.999, epsilon=1e-06, momentum=0.9, rho=0.95, initial_accumulator_value=0.1).\u001b[0m\n",
      "\u001b[34mIgnoring unrecognized arguments: ['--use_fp16', 'True'].\u001b[0m\n",
      "\u001b[34mNumber of class labels: 2\u001b[0m\n",
      "\u001b[34mCardinality of dataset 5572\u001b[0m\n",
      "\u001b[34mNumber of training examples: 4457\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 1115\u001b[0m\n",
      "\u001b[34m'_input_model_extracted/__models_info__.json' file could not be found.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\u001b[0m\n",
      "\u001b[34mNo training configuration found in save file, so the model was *not* compiled. Compile it manually.\u001b[0m\n",
      "\u001b[34mAttaching a randomly initialized classification layer on top of the original encoder layer model to classify input text to one of the 2 classes.\u001b[0m\n",
      "\u001b[34mModel: \"model\"\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mtext (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':\u001b[0m\n",
      "\u001b[34m(None, 128)}\u001b[0m\n",
      "\u001b[34mkeras_layer_1 (KerasLayer)     {'default': (None,   177853441   ['keras_layer[1][0]',            \n",
      "                                768),                             'keras_layer[1][1]',\u001b[0m\n",
      "\u001b[34m'encoder_outputs':               'keras_layer[1][2]']            \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),\u001b[0m\n",
      "\u001b[34m(None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),\u001b[0m\n",
      "\u001b[34m(None, 128, 768)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[1][13]']         \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 2)            1538        ['dropout[0][0]']                \n",
      "                                                                                                  \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 177,854,979\u001b[0m\n",
      "\u001b[34mTrainable params: 1,538\u001b[0m\n",
      "\u001b[34mNon-trainable params: 177,853,441\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34musing Adamw optimizer\u001b[0m\n",
      "\u001b[34mgradient_clip_norm=1.000000\u001b[0m\n",
      "\u001b[34mSetting the evaluation metric to: val_accuracy.\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34mExtension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\u001b[0m\n",
      "\u001b[34mIf this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\u001b[0m\n",
      "\u001b[34mWarning! MPI libs are missing, but python applications are still available.\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:49.852 algo-1:51 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.088 algo-1:51 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.109 algo-1:51 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.109 algo-1:51 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.110 algo-1:51 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.110 algo-1:51 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-03-10 17:59:50.110 algo-1:51 INFO hook.py:427] Monitoring the collections: sm_metrics, losses, gradients, metrics\u001b[0m\n",
      "\u001b[34m70/70 - 308s - loss: 0.6924 - accuracy: 0.6338 - val_loss: 0.6106 - val_accuracy: 0.8448 - 308s/epoch - 4s/step\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m70/70 - 295s - loss: 0.5746 - accuracy: 0.8106 - val_loss: 0.5217 - val_accuracy: 0.8628 - 295s/epoch - 4s/step\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m70/70 - 293s - loss: 0.5189 - accuracy: 0.8526 - val_loss: 0.4826 - val_accuracy: 0.8610 - 293s/epoch - 4s/step\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m70/70 - 292s - loss: 0.4851 - accuracy: 0.8634 - val_loss: 0.4673 - val_accuracy: 0.8610 - 292s/epoch - 4s/step\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m70/70 - 292s - loss: 0.4739 - accuracy: 0.8658 - val_loss: 0.4637 - val_accuracy: 0.8610 - 292s/epoch - 4s/step\u001b[0m\n",
      "\u001b[34mSetting weights to model achieving the maximum val_accuracy: 0.8627802729606628 at epoch 2/5\u001b[0m\n",
      "\u001b[34mSaving the model with the highest val_accuracy for running inference or incremental training.\u001b[0m\n",
      "\u001b[34mFound untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 364). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mAssets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mInfo file not found at '_input_model_extracted/__models_info__.json'.\u001b[0m\n",
      "\u001b[34m2025-03-10 18:24:45,168 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-03-10 18:24:45,168 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-03-10 18:24:45,169 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-03-10 18:25:13 Uploading - Uploading generated training model\n",
      "2025-03-10 18:25:13 Completed - Training job completed\n",
      "Training seconds: 1641\n",
      "Billable seconds: 1641\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e4c77-680f-420b-958d-f0666bf901e3",
   "metadata": {},
   "source": [
    "Checking debugger results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42adaa0c-0b1d-4eb3-be50-8b72fa3df077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossNotDecreasing:  NoIssuesFound\n",
      "Overfit:  NoIssuesFound\n",
      "VanishingGradient:  NoIssuesFound\n"
     ]
    }
   ],
   "source": [
    "for rule in estimator.latest_training_job.rule_job_summary():\n",
    "    print(f\"{rule['RuleConfigurationName']}:  {rule['RuleEvaluationStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156baf4-87d9-44f7-b7ae-c81bcecac700",
   "metadata": {},
   "source": [
    "Choose serverless endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896fa1e-5fdf-418c-869b-bc1676820243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=2048,  # Choose from 1024, 2048, 3072, 4096, 5120, 6144 MB\n",
    "    max_concurrency=10       # Max concurrent invocations\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491975bf-0155-4b3e-8160-2adca7cb1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-06-02-48-07-356\n",
      "INFO:sagemaker:Creating endpoint-config with name tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-06-02-48-07-355\n",
      "INFO:sagemaker:Creating endpoint with name tf-tc-bert-multi-cased-l-12-h-768-a-12--2025-03-06-02-48-07-355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(instance_type=\"ml.m5.xlarge\", initial_instance_count=1, serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea9a9e5c-fa57-4760-bed2-eaf6f2fd6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Thanks for your subscription to Ringtone UK your mobile will be charged\", \n",
    "     \"とにかく安い、安すぎる。今すぐクリック \", \n",
    "     \"いまのところは雨は降ってないです。\",\n",
    "     \"今日の学校は忙しかったですか？\",\n",
    "    \"今ならお買い得、買うなら今！！\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d37ca89e-6d8b-486e-9b0c-eb168b0717c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probabilities': [0.614778221, 0.385221839]}\n",
      "{'probabilities': [0.620334804, 0.379665226]}\n",
      "{'probabilities': [0.422047585, 0.577952385]}\n",
      "{'probabilities': [0.473016113, 0.526983917]}\n",
      "{'probabilities': [0.511945069, 0.488054901]}\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    query_response = predictor.predict(text)\n",
    "    print(query_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c22ffc-8540-4ccf-8c77-7d882c14e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f048a9b-a1b0-4650-bedf-ad70844bbe87",
   "metadata": {},
   "source": [
    "**Code below also works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a190d-9449-4926-83a1-5d1dad1de251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "from sagemaker.jumpstart.utils import get_jumpstart_content_bucket\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "training_input = TrainingInput(\n",
    "    \"s3://sagemaker-automated-execution-533267358966-ap-northeast-1/data.csv\",\n",
    "    content_type=\"text/csv\"\n",
    "    )\n",
    "\n",
    "estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    hyperparameters={\"epochs\": \"1\", \"batch_size\": \"64\",  \"use_fp16\": \"True\", \"train_only_top_layer\":\"True\"},\n",
    "    instance_type= \"ml.m5.4xlarge\",\n",
    "    )\n",
    "\n",
    "estimator.hyperparameters()\n",
    "\n",
    "estimator.fit({\"training\": training_input}, logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
